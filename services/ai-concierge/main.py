"""
AeroFusionXR AI Concierge Service
===============================

Enterprise-grade conversational AI service for the AeroFusionXR Aviation Platform.

Features:
- ðŸ§  Advanced multimodal query processing (text, voice, image, video)
- ðŸŽ¯ Intelligent intent classification and routing
- ðŸ’¬ Context-aware conversation management
- ðŸŒ Multi-language support with real-time translation
- ðŸ”Š Voice synthesis and recognition
- ðŸŽ¨ Computer vision for visual queries
- ðŸ“Š Real-time sentiment analysis
- ðŸš€ High-performance async processing
- ðŸ“ˆ Comprehensive monitoring and observability
- ðŸ›¡ï¸ Enterprise security and rate limiting

Architecture:
- FastAPI with async/await for high concurrency
- Redis for session management and caching
- PostgreSQL for conversation history and analytics
- OpenAI/Azure AI for natural language processing
- AWS Polly/Azure Speech for voice synthesis
- Computer vision models for image processing
- Real-time WebSocket support for live conversations

Author: AeroFusionXR Team
License: Proprietary
"""

import asyncio
import json
import logging
import os
import time
import uuid
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union

import aiofiles
import aioredis
import asyncpg
import httpx
from fastapi import (
    FastAPI, HTTPException, Depends, WebSocket, WebSocketDisconnect,
    UploadFile, File, Form, BackgroundTasks, Request, Response
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from pydantic import BaseModel, Field, validator
import speech_recognition as sr
import pyttsx3
from transformers import pipeline, AutoTokenizer, AutoModel
import torch
import cv2
import numpy as np
from PIL import Image
import io
import base64

# ================================
# CONFIGURATION & INITIALIZATION
# ================================

# Environment configuration with secure defaults
CONFIG = {
    "SERVICE_NAME": "ai-concierge",
    "VERSION": "1.0.0",
    "PORT": int(os.getenv("PORT", 8000)),
    "REDIS_URL": os.getenv("REDIS_URL", "redis://localhost:6379"),
    "DATABASE_URL": os.getenv("DATABASE_URL", "postgresql://user:pass@localhost/concierge"),
    "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""),
    "AZURE_SPEECH_KEY": os.getenv("AZURE_SPEECH_KEY", ""),
    "AZURE_SPEECH_REGION": os.getenv("AZURE_SPEECH_REGION", ""),
    "AWS_ACCESS_KEY_ID": os.getenv("AWS_ACCESS_KEY_ID", ""),
    "AWS_SECRET_ACCESS_KEY": os.getenv("AWS_SECRET_ACCESS_KEY", ""),
    "AWS_REGION": os.getenv("AWS_REGION", "us-east-1"),
    "LOG_LEVEL": os.getenv("LOG_LEVEL", "INFO"),
    "MAX_CONVERSATION_HISTORY": int(os.getenv("MAX_CONVERSATION_HISTORY", 50)),
    "SESSION_TIMEOUT_MINUTES": int(os.getenv("SESSION_TIMEOUT_MINUTES", 30)),
    "MAX_FILE_SIZE_MB": int(os.getenv("MAX_FILE_SIZE_MB", 10)),
    "SUPPORTED_LANGUAGES": os.getenv("SUPPORTED_LANGUAGES", "en,es,fr,de,ja,zh,ar").split(","),
    "DEFAULT_LANGUAGE": os.getenv("DEFAULT_LANGUAGE", "en"),
    "ENABLE_VOICE_SYNTHESIS": os.getenv("ENABLE_VOICE_SYNTHESIS", "true").lower() == "true",
    "ENABLE_COMPUTER_VISION": os.getenv("ENABLE_COMPUTER_VISION", "true").lower() == "true",
    "RATE_LIMIT_PER_MINUTE": int(os.getenv("RATE_LIMIT_PER_MINUTE", 60)),
    "MAX_CONCURRENT_SESSIONS": int(os.getenv("MAX_CONCURRENT_SESSIONS", 1000))
}

# Configure structured logging
logging.basicConfig(
    level=getattr(logging, CONFIG["LOG_LEVEL"]),
    format='{"timestamp": "%(asctime)s", "level": "%(levelname)s", "service": "ai-concierge", "message": "%(message)s", "module": "%(name)s"}',
    datefmt='%Y-%m-%dT%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Configure OpenTelemetry distributed tracing
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

# Configure OTLP trace exporter for observability
otlp_exporter = OTLPSpanExporter(
    endpoint=os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT", "http://jaeger:14268/api/traces"),
    insecure=True
)
span_processor = BatchSpanProcessor(otlp_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# Configure Prometheus metrics with comprehensive coverage
METRICS = {
    "queries_total": Counter(
        "ai_concierge_queries_total",
        "Total number of queries processed",
        ["query_type", "language", "intent", "status"]
    ),
    "query_duration": Histogram(
        "ai_concierge_query_duration_seconds",
        "Time spent processing queries",
        ["query_type", "intent"]
    ),
    "active_sessions": Gauge(
        "ai_concierge_active_sessions",
        "Number of active conversation sessions"
    ),
    "model_inference_time": Histogram(
        "ai_concierge_model_inference_seconds",
        "Time spent on ML model inference",
        ["model_type"]
    ),
    "conversation_turns": Counter(
        "ai_concierge_conversation_turns_total",
        "Total conversation turns",
        ["session_type"]
    ),
    "sentiment_scores": Histogram(
        "ai_concierge_sentiment_scores",
        "Distribution of sentiment analysis scores"
    ),
    "language_detection": Counter(
        "ai_concierge_language_detections_total",
        "Language detection counts",
        ["detected_language", "confidence_level"]
    ),
    "voice_synthesis_requests": Counter(
        "ai_concierge_voice_synthesis_total",
        "Voice synthesis requests",
        ["language", "voice_type", "status"]
    ),
    "image_processing_requests": Counter(
        "ai_concierge_image_processing_total",
        "Image processing requests",
        ["image_type", "processing_type", "status"]
    )
}

# ================================
# APPLICATION STATE MANAGEMENT
# ================================

class ApplicationState:
    """
    Centralized application state management for the AI Concierge service.
    
    Manages:
    - Database connections (Redis, PostgreSQL)
    - ML model loading and caching
    - Active WebSocket sessions
    - Background tasks and workers
    - Resource cleanup
    """
    
    def __init__(self):
        self.redis: Optional[aioredis.Redis] = None
        self.db_pool: Optional[asyncpg.Pool] = None
        self.http_client: Optional[httpx.AsyncClient] = None
        self.active_sessions: Dict[str, Dict[str, Any]] = {}
        self.websocket_connections: Dict[str, WebSocket] = {}
        
        # ML Models (lazy loaded for performance)
        self.intent_classifier = None
        self.sentiment_analyzer = None
        self.language_detector = None
        self.conversation_model = None
        self.vision_model = None
        self.translation_model = None
        
        # Voice processing components
        self.speech_recognizer = None
        self.voice_synthesizer = None
        
        # Performance tracking
        self.startup_time = datetime.utcnow()
        self.total_queries_processed = 0
        self.cache_hit_rate = 0.0

app_state = ApplicationState()

# ================================
# PYDANTIC MODELS & SCHEMAS
# ================================

class QueryRequest(BaseModel):
    """
    Comprehensive query request model supporting multimodal inputs.
    """
    session_id: str = Field(..., description="Unique session identifier")
    query_text: Optional[str] = Field(None, description="Text query input")
    language: str = Field(default="en", description="Query language (ISO 639-1 code)")
    user_id: Optional[str] = Field(None, description="User identifier for personalization")
    context: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional context")
    preferences: Optional[Dict[str, Any]] = Field(default_factory=dict, description="User preferences")
    location: Optional[Dict[str, float]] = Field(None, description="User location (lat, lng, alt)")
    flight_info: Optional[Dict[str, str]] = Field(None, description="Current flight information")
    enable_voice_response: bool = Field(default=False, description="Generate voice response")
    response_format: str = Field(default="json", description="Response format (json, ssml, text)")
    priority: str = Field(default="normal", description="Query priority (low, normal, high, urgent)")
    
    @validator('language')
    def validate_language(cls, v):
        if v not in CONFIG["SUPPORTED_LANGUAGES"]:
            raise ValueError(f"Unsupported language: {v}")
        return v
    
    @validator('priority')
    def validate_priority(cls, v):
        if v not in ["low", "normal", "high", "urgent"]:
            raise ValueError("Priority must be one of: low, normal, high, urgent")
        return v

class IntentRequest(BaseModel):
    """Intent classification request model."""
    text: str = Field(..., description="Text to classify")
    context: Optional[Dict[str, Any]] = Field(default_factory=dict)
    user_profile: Optional[Dict[str, Any]] = Field(default_factory=dict)

class VoiceRequest(BaseModel):
    """Voice processing request model."""
    session_id: str
    audio_format: str = Field(default="wav", description="Audio format (wav, mp3, m4a)")
    sample_rate: int = Field(default=16000, description="Audio sample rate")
    language: str = Field(default="en")

class ImageRequest(BaseModel):
    """Image processing request model."""
    session_id: str
    image_type: str = Field(..., description="Image type (terminal_map, gate_info, menu, document)")
    processing_type: str = Field(default="ocr", description="Processing type (ocr, object_detection, scene_analysis)")
    language: str = Field(default="en")

class ConversationResponse(BaseModel):
    """
    Comprehensive conversation response model.
    """
    session_id: str
    response_text: str
    intent: str
    confidence: float = Field(..., ge=0.0, le=1.0)
    entities: List[Dict[str, Any]] = Field(default_factory=list)
    sentiment: Dict[str, float] = Field(default_factory=dict)
    suggested_actions: List[Dict[str, Any]] = Field(default_factory=list)
    voice_response_url: Optional[str] = None
    follow_up_questions: List[str] = Field(default_factory=list)
    context_updates: Dict[str, Any] = Field(default_factory=dict)
    response_time_ms: float
    language: str
    requires_human_handoff: bool = Field(default=False)
    escalation_reason: Optional[str] = None
    related_services: List[str] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)

# ================================
# AI MODEL INITIALIZATION
# ================================

async def initialize_ai_models():
    """
    Initialize all AI/ML models with proper error handling and performance monitoring.
    
    Models loaded:
    - Intent classification (aviation domain-specific)
    - Sentiment analysis (multilingual)
    - Language detection
    - Conversational AI (fine-tuned for aviation)
    - Computer vision (OCR, object detection)
    - Translation models
    """
    logger.info("ðŸ§  Initializing AI models...")
    
    try:
        # Intent Classification Model (aviation domain-specific)
        logger.info("Loading intent classification model...")
        app_state.intent_classifier = pipeline(
            "text-classification",
            model="microsoft/DialoGPT-medium",  # Replace with aviation-specific model
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Sentiment Analysis Model (multilingual support)
        logger.info("Loading sentiment analysis model...")
        app_state.sentiment_analyzer = pipeline(
            "sentiment-analysis",
            model="cardiffnlp/twitter-roberta-base-sentiment-latest",
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Language Detection Model
        logger.info("Loading language detection model...")
        app_state.language_detector = pipeline(
            "text-classification",
            model="papluca/xlm-roberta-base-language-detection",
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Conversational AI Model (aviation fine-tuned)
        logger.info("Loading conversational AI model...")
        app_state.conversation_model = pipeline(
            "conversational",
            model="microsoft/DialoGPT-large",  # Replace with aviation-specific model
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Computer Vision Model (if enabled)
        if CONFIG["ENABLE_COMPUTER_VISION"]:
            logger.info("Loading computer vision models...")
            app_state.vision_model = {
                "ocr": pipeline("image-to-text", model="microsoft/trocr-base-printed"),
                "object_detection": pipeline("object-detection", model="facebook/detr-resnet-50"),
                "scene_analysis": pipeline("image-classification", model="google/vit-base-patch16-224")
            }
        
        # Voice Processing (if enabled)
        if CONFIG["ENABLE_VOICE_SYNTHESIS"]:
            logger.info("Initializing voice processing...")
            app_state.speech_recognizer = sr.Recognizer()
            app_state.voice_synthesizer = pyttsx3.init()
            
            # Configure voice synthesizer
            voices = app_state.voice_synthesizer.getProperty('voices')
            if voices:
                app_state.voice_synthesizer.setProperty('voice', voices[0].id)
            app_state.voice_synthesizer.setProperty('rate', 180)
            app_state.voice_synthesizer.setProperty('volume', 0.8)
        
        logger.info("âœ… All AI models initialized successfully")
        
    except Exception as e:
        logger.error(f"âŒ Failed to initialize AI models: {e}")
        raise

# ================================
# INTENT CLASSIFICATION ENGINE
# ================================

class IntentClassifier:
    """
    Advanced intent classification engine for aviation domain queries.
    
    Supports intents:
    - flight_info: Flight status, schedules, delays
    - navigation: Terminal directions, gate finding
    - services: Restaurant recommendations, shopping
    - booking: Flight changes, upgrades, cancellations
    - baggage: Baggage tracking, claims, restrictions
    - assistance: Special needs, customer service
    - emergency: Medical, security, urgent situations
    """
    
    # Aviation domain intent mapping with confidence thresholds
    INTENT_MAPPING = {
        "flight_info": {
            "keywords": ["flight", "departure", "arrival", "delay", "gate", "status", "schedule"],
            "patterns": [r"flight\s+\w+", r"when.*depart", r"what.*gate", r"arrival.*time"],
            "confidence_threshold": 0.7
        },
        "navigation": {
            "keywords": ["where", "direction", "find", "locate", "map", "terminal", "bathroom", "restaurant"],
            "patterns": [r"where.*is", r"how.*get.*to", r"directions.*to", r"find.*nearest"],
            "confidence_threshold": 0.6
        },
        "services": {
            "keywords": ["food", "restaurant", "shop", "wifi", "lounge", "service", "amenity"],
            "patterns": [r"need.*eat", r"where.*buy", r"wifi.*password", r"lounge.*access"],
            "confidence_threshold": 0.6
        },
        "booking": {
            "keywords": ["book", "change", "cancel", "upgrade", "seat", "reservation", "ticket"],
            "patterns": [r"change.*flight", r"cancel.*booking", r"upgrade.*seat", r"select.*seat"],
            "confidence_threshold": 0.8
        },
        "baggage": {
            "keywords": ["bag", "luggage", "suitcase", "carry-on", "check-in", "claim", "lost"],
            "patterns": [r"lost.*bag", r"baggage.*claim", r"check.*bag", r"carry.*on"],
            "confidence_threshold": 0.7
        },
        "assistance": {
            "keywords": ["help", "assist", "support", "wheelchair", "special", "medical", "customer"],
            "patterns": [r"need.*help", r"customer.*service", r"special.*assistance"],
            "confidence_threshold": 0.5
        },
        "emergency": {
            "keywords": ["emergency", "urgent", "medical", "security", "police", "fire", "evacuation"],
            "patterns": [r"emergency", r"need.*medical", r"security.*issue", r"urgent.*help"],
            "confidence_threshold": 0.9
        }
    }
    
    @staticmethod
    async def classify_intent(text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Classify user intent using multiple approaches for high accuracy.
        
        Uses:
        1. Keyword matching with TF-IDF scoring
        2. Pattern matching with regex
        3. ML model classification
        4. Context-aware scoring adjustments
        
        Returns:
            Dict containing intent, confidence, entities, and reasoning
        """
        with tracer.start_as_current_span("intent_classification") as span:
            start_time = time.time()
            
            try:
                text_lower = text.lower()
                intent_scores = {}
                entities = []
                
                # Method 1: Keyword-based scoring
                for intent, config in IntentClassifier.INTENT_MAPPING.items():
                    score = 0.0
                    matched_keywords = []
                    
                    # Check keywords
                    for keyword in config["keywords"]:
                        if keyword in text_lower:
                            score += 1.0
                            matched_keywords.append(keyword)
                    
                    # Check patterns
                    import re
                    for pattern in config["patterns"]:
                        if re.search(pattern, text_lower):
                            score += 2.0  # Patterns weighted higher
                    
                    # Normalize score
                    if score > 0:
                        normalized_score = min(score / (len(config["keywords"]) + len(config["patterns"])), 1.0)
                        intent_scores[intent] = {
                            "score": normalized_score,
                            "matched_keywords": matched_keywords,
                            "method": "keyword_pattern"
                        }
                
                # Method 2: ML model classification (if available)
                if app_state.intent_classifier:
                    try:
                        ml_result = app_state.intent_classifier(text)
                        if ml_result and len(ml_result) > 0:
                            ml_intent = ml_result[0]["label"].lower()
                            ml_confidence = ml_result[0]["score"]
                            
                            # Map ML result to our intent system
                            if ml_intent in intent_scores:
                                intent_scores[ml_intent]["score"] = max(
                                    intent_scores[ml_intent]["score"],
                                    ml_confidence
                                )
                                intent_scores[ml_intent]["method"] = "ml_enhanced"
                            else:
                                intent_scores[ml_intent] = {
                                    "score": ml_confidence,
                                    "matched_keywords": [],
                                    "method": "ml_only"
                                }
                    except Exception as e:
                        logger.warning(f"ML intent classification failed: {e}")
                
                # Method 3: Context-aware adjustments
                if context:
                    # Boost certain intents based on context
                    if context.get("location_type") == "gate_area":
                        intent_scores.get("flight_info", {})["score"] = \
                            intent_scores.get("flight_info", {}).get("score", 0) + 0.2
                    
                    if context.get("time_to_departure", 0) < 60:  # Less than 1 hour
                        intent_scores.get("flight_info", {})["score"] = \
                            intent_scores.get("flight_info", {}).get("score", 0) + 0.1
                
                # Determine final intent
                if not intent_scores:
                    final_intent = "general_inquiry"
                    confidence = 0.3
                    reasoning = "No specific intent patterns matched"
                else:
                    # Get highest scoring intent
                    best_intent = max(intent_scores.items(), key=lambda x: x[1]["score"])
                    final_intent = best_intent[0]
                    confidence = best_intent[1]["score"]
                    reasoning = f"Classified via {best_intent[1]['method']}"
                    
                    # Extract entities for the classified intent
                    entities = IntentClassifier._extract_entities(text, final_intent)
                
                # Check confidence threshold
                threshold = IntentClassifier.INTENT_MAPPING.get(
                    final_intent, {}
                ).get("confidence_threshold", 0.5)
                
                if confidence < threshold:
                    final_intent = "clarification_needed"
                    reasoning = f"Confidence {confidence:.2f} below threshold {threshold}"
                
                processing_time = time.time() - start_time
                
                # Update metrics
                METRICS["model_inference_time"].labels(model_type="intent_classifier").observe(processing_time)
                
                # Update tracing
                span.set_attribute("intent.classified", final_intent)
                span.set_attribute("intent.confidence", confidence)
                span.set_attribute("intent.processing_time", processing_time)
                
                result = {
                    "intent": final_intent,
                    "confidence": confidence,
                    "entities": entities,
                    "reasoning": reasoning,
                    "processing_time_ms": processing_time * 1000,
                    "alternative_intents": [
                        {"intent": k, "confidence": v["score"]}
                        for k, v in sorted(intent_scores.items(), key=lambda x: x[1]["score"], reverse=True)[:3]
                    ]
                }
                
                logger.info(f"Intent classified: {final_intent} (confidence: {confidence:.2f})")
                return result
                
            except Exception as e:
                span.record_exception(e)
                logger.error(f"Intent classification error: {e}")
                return {
                    "intent": "error",
                    "confidence": 0.0,
                    "entities": [],
                    "reasoning": f"Classification failed: {str(e)}",
                    "processing_time_ms": (time.time() - start_time) * 1000,
                    "alternative_intents": []
                }
    
    @staticmethod
    def _extract_entities(text: str, intent: str) -> List[Dict[str, Any]]:
        """Extract relevant entities based on classified intent."""
        entities = []
        text_lower = text.lower()
        
        # Entity extraction patterns by intent
        entity_patterns = {
            "flight_info": {
                "flight_number": r"[A-Z]{2,3}\s*\d{3,4}",
                "gate": r"gate\s*([A-Z]?\d+[A-Z]?)",
                "time": r"\d{1,2}:\d{2}(?:\s*[AP]M)?",
                "airline": r"(united|delta|american|southwest|jetblue|alaska|spirit)"
            },
            "navigation": {
                "location": r"(terminal\s*[A-Z]?|gate\s*[A-Z]?\d+|bathroom|restaurant|security|baggage\s*claim)",
                "direction": r"(north|south|east|west|left|right|up|down|level\s*\d+)"
            },
            "booking": {
                "confirmation": r"[A-Z0-9]{6,8}",
                "seat": r"(\d{1,2}[A-F]|aisle|window|middle)",
                "class": r"(economy|business|first|premium)"
            }
        }
        
        import re
        patterns = entity_patterns.get(intent, {})
        
        for entity_type, pattern in patterns.items():
            matches = re.findall(pattern, text_lower, re.IGNORECASE)
            for match in matches:
                entities.append({
                    "type": entity_type,
                    "value": match if isinstance(match, str) else match[0],
                    "confidence": 0.8,
                    "start_index": text_lower.find(match if isinstance(match, str) else match[0]),
                    "end_index": text_lower.find(match if isinstance(match, str) else match[0]) + len(match if isinstance(match, str) else match[0])
                })
        
        return entities

# ================================
# CONVERSATION MANAGEMENT
# ================================

class ConversationManager:
    """
    Advanced conversation management with context tracking, personalization, and multi-turn dialog support.
    """
    
    @staticmethod
    async def process_query(request: QueryRequest) -> ConversationResponse:
        """
        Process a complete query with full context awareness and multi-modal support.
        """
        with tracer.start_as_current_span("conversation_processing") as span:
            start_time = time.time()
            
            try:
                # Update session activity
                await ConversationManager._update_session_activity(request.session_id)
                
                # Get conversation context
                context = await ConversationManager._get_conversation_context(request.session_id)
                
                # Merge request context with session context
                full_context = {**context, **(request.context or {})}
                
                # Classify intent
                intent_result = await IntentClassifier.classify_intent(
                    request.query_text or "",
                    full_context
                )
                
                # Analyze sentiment
                sentiment = await ConversationManager._analyze_sentiment(request.query_text or "")
                
                # Generate response based on intent
                response_text, suggested_actions, related_services = await ConversationManager._generate_response(
                    intent_result["intent"],
                    request.query_text or "",
                    intent_result["entities"],
                    full_context,
                    request.preferences or {}
                )
                
                # Generate follow-up questions
                follow_up_questions = await ConversationManager._generate_follow_up_questions(
                    intent_result["intent"],
                    intent_result["entities"],
                    full_context
                )
                
                # Check if human handoff is needed
                requires_handoff, escalation_reason = ConversationManager._check_escalation_criteria(
                    intent_result,
                    sentiment,
                    full_context
                )
                
                # Generate voice response if requested
                voice_response_url = None
                if request.enable_voice_response and CONFIG["ENABLE_VOICE_SYNTHESIS"]:
                    voice_response_url = await ConversationManager._generate_voice_response(
                        response_text,
                        request.language
                    )
                
                # Update conversation context
                context_updates = {
                    "last_intent": intent_result["intent"],
                    "last_entities": intent_result["entities"],
                    "conversation_turn": context.get("conversation_turn", 0) + 1,
                    "last_query_time": datetime.utcnow().isoformat(),
                    "cumulative_sentiment": ConversationManager._update_cumulative_sentiment(
                        context.get("cumulative_sentiment", {"compound": 0.0, "count": 0}),
                        sentiment
                    )
                }
                
                await ConversationManager._update_conversation_context(
                    request.session_id,
                    context_updates
                )
                
                # Store conversation turn for analytics
                await ConversationManager._store_conversation_turn(
                    request.session_id,
                    request.query_text or "",
                    response_text,
                    intent_result,
                    sentiment,
                    request.user_id
                )
                
                processing_time = time.time() - start_time
                
                # Update metrics
                METRICS["queries_total"].labels(
                    query_type="text",
                    language=request.language,
                    intent=intent_result["intent"],
                    status="success"
                ).inc()
                
                METRICS["query_duration"].labels(
                    query_type="text",
                    intent=intent_result["intent"]
                ).observe(processing_time)
                
                METRICS["conversation_turns"].labels(
                    session_type="standard"
                ).inc()
                
                METRICS["sentiment_scores"].observe(sentiment.get("compound", 0.0))
                
                # Create comprehensive response
                response = ConversationResponse(
                    session_id=request.session_id,
                    response_text=response_text,
                    intent=intent_result["intent"],
                    confidence=intent_result["confidence"],
                    entities=intent_result["entities"],
                    sentiment=sentiment,
                    suggested_actions=suggested_actions,
                    voice_response_url=voice_response_url,
                    follow_up_questions=follow_up_questions,
                    context_updates=context_updates,
                    response_time_ms=processing_time * 1000,
                    language=request.language,
                    requires_human_handoff=requires_handoff,
                    escalation_reason=escalation_reason,
                    related_services=related_services,
                    metadata={
                        "model_versions": {
                            "intent_classifier": "1.0",
                            "sentiment_analyzer": "1.0",
                            "conversation_model": "1.0"
                        },
                        "processing_pipeline": "standard",
                        "context_length": len(str(full_context)),
                        "alternative_intents": intent_result["alternative_intents"]
                    }
                )
                
                # Update tracing
                span.set_attribute("conversation.session_id", request.session_id)
                span.set_attribute("conversation.intent", intent_result["intent"])
                span.set_attribute("conversation.confidence", intent_result["confidence"])
                span.set_attribute("conversation.sentiment", sentiment.get("compound", 0.0))
                span.set_attribute("conversation.processing_time", processing_time)
                span.set_attribute("conversation.requires_handoff", requires_handoff)
                
                return response
                
            except Exception as e:
                span.record_exception(e)
                logger.error(f"Conversation processing error: {e}")
                
                # Update error metrics
                METRICS["queries_total"].labels(
                    query_type="text",
                    language=request.language,
                    intent="error",
                    status="error"
                ).inc()
                
                # Return error response
                return ConversationResponse(
                    session_id=request.session_id,
                    response_text="I apologize, but I'm experiencing technical difficulties. Please try again or contact customer service for assistance.",
                    intent="error",
                    confidence=0.0,
                    entities=[],
                    sentiment={"compound": 0.0, "positive": 0.0, "negative": 0.0, "neutral": 1.0},
                    suggested_actions=[{
                        "type": "contact_support",
                        "title": "Contact Customer Service",
                        "description": "Speak with a human agent"
                    }],
                    follow_up_questions=[],
                    context_updates={},
                    response_time_ms=(time.time() - start_time) * 1000,
                    language=request.language,
                    requires_human_handoff=True,
                    escalation_reason="technical_error",
                    related_services=["customer-service"],
                    metadata={"error": str(e)}
                )
    
    @staticmethod
    async def _generate_response(
        intent: str,
        query_text: str,
        entities: List[Dict[str, Any]],
        context: Dict[str, Any],
        preferences: Dict[str, Any]
    ) -> tuple[str, List[Dict[str, Any]], List[str]]:
        """Generate contextual response based on intent and entities."""
        
        # Aviation domain response templates
        response_templates = {
            "flight_info": {
                "base": "I'll help you with flight information. ",
                "with_flight_number": "Let me look up details for flight {flight_number}. ",
                "general": "What specific flight information would you like to know? I can provide details about departures, arrivals, delays, and gate assignments."
            },
            "navigation": {
                "base": "I can help you navigate the airport. ",
                "to_location": "To get to {location}, ",
                "general": "Where would you like to go? I can provide directions to gates, restaurants, bathrooms, baggage claim, and other airport facilities."
            },
            "services": {
                "base": "I'd be happy to help you find airport services. ",
                "food": "For dining options, ",
                "general": "What services are you looking for? I can help you find restaurants, shops, lounges, WiFi, and other amenities."
            },
            "booking": {
                "base": "I can assist with your booking needs. ",
                "change": "To modify your reservation, ",
                "general": "What would you like to do with your booking? I can help with seat selection, upgrades, changes, and cancellations."
            },
            "baggage": {
                "base": "I'm here to help with baggage-related questions. ",
                "lost": "For lost baggage, ",
                "general": "What do you need help with regarding baggage? I can assist with tracking, claims, restrictions, and check-in procedures."
            },
            "assistance": {
                "base": "I'm ready to assist you. ",
                "special_needs": "For special assistance services, ",
                "general": "How can I help you today? I can connect you with customer service, special assistance, or other support services."
            },
            "emergency": {
                "base": "This seems urgent. ",
                "medical": "For medical emergencies, please contact airport medical services immediately or call 911. ",
                "general": "For urgent situations, I recommend contacting airport security or customer service immediately."
            }
        }
        
        # Extract flight number if present
        flight_number = None
        location = None
        for entity in entities:
            if entity["type"] == "flight_number":
                flight_number = entity["value"]
            elif entity["type"] == "location":
                location = entity["value"]
        
        # Generate base response
        template = response_templates.get(intent, {"base": "I understand you're asking about ", "general": "How can I assist you further?"})
        
        if intent == "flight_info" and flight_number:
            response = template["base"] + template["with_flight_number"].format(flight_number=flight_number)
            response += f"Based on current data, I'll fetch the latest information for flight {flight_number}."
        elif intent == "navigation" and location:
            response = template["base"] + template["to_location"].format(location=location)
            response += f"I'll provide you with the best route to {location}."
        else:
            response = template["base"] + template["general"]
        
        # Add context-aware enhancements
        if context.get("frequent_flyer_tier") in ["gold", "platinum", "diamond"]:
            response += " As a valued frequent flyer, I can also help you access premium services."
        
        if context.get("time_to_departure", 0) < 60:
            response += " I notice your departure time is approaching - let me prioritize urgent information."
        
        # Generate suggested actions based on intent
        suggested_actions = ConversationManager._get_suggested_actions(intent, entities, context)
        
        # Determine related services
        related_services = ConversationManager._get_related_services(intent)
        
        return response, suggested_actions, related_services
    
    @staticmethod
    def _get_suggested_actions(intent: str, entities: List[Dict], context: Dict) -> List[Dict[str, Any]]:
        """Generate contextual suggested actions."""
        actions = []
        
        action_mapping = {
            "flight_info": [
                {"type": "check_status", "title": "Check Flight Status", "description": "Get real-time flight updates"},
                {"type": "view_gate", "title": "Find Gate", "description": "Get directions to your gate"},
                {"type": "set_alerts", "title": "Set Alerts", "description": "Get notified of flight changes"}
            ],
            "navigation": [
                {"type": "get_directions", "title": "Get Directions", "description": "Turn-by-turn navigation"},
                {"type": "view_map", "title": "View Map", "description": "Interactive airport map"},
                {"type": "find_nearby", "title": "Find Nearby", "description": "Discover nearby amenities"}
            ],
            "services": [
                {"type": "browse_dining", "title": "Browse Dining", "description": "View restaurant options"},
                {"type": "find_shopping", "title": "Find Shopping", "description": "Discover retail stores"},
                {"type": "access_wifi", "title": "WiFi Access", "description": "Connect to airport WiFi"}
            ],
            "booking": [
                {"type": "manage_booking", "title": "Manage Booking", "description": "View and modify your reservation"},
                {"type": "select_seat", "title": "Select Seat", "description": "Choose or change your seat"},
                {"type": "upgrade_class", "title": "Upgrade", "description": "Upgrade your travel class"}
            ],
            "assistance": [
                {"type": "contact_support", "title": "Contact Support", "description": "Speak with customer service"},
                {"type": "request_assistance", "title": "Request Assistance", "description": "Get help from airport staff"},
                {"type": "emergency_contact", "title": "Emergency", "description": "Emergency contact information"}
            ]
        }
        
        return action_mapping.get(intent, [])
    
    @staticmethod
    def _get_related_services(intent: str) -> List[str]:
        """Get related microservices for the intent."""
        service_mapping = {
            "flight_info": ["flight-info", "booking"],
            "navigation": ["wayfinding"],
            "services": ["commerce", "wayfinding"],
            "booking": ["booking", "flight-info"],
            "baggage": ["baggage-tracker"],
            "assistance": ["customer-service"],
            "emergency": ["customer-service", "security"]
        }
        
        return service_mapping.get(intent, [])

# Continue with remaining implementation... 