{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 0,
  "id": 1,
  "links": [],
  "panels": [
    {
      "title": "Service Health",
      "type": "row",
      "panels": [
        {
          "title": "Service Status",
          "type": "stat",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "up{job=\"ai-concierge\"}"
            }
          ],
          "fieldConfig": {
            "defaults": {
              "mappings": [
                {
                  "from": "0",
                  "text": "Down",
                  "to": "0",
                  "type": 1,
                  "value": "0"
                },
                {
                  "from": "1",
                  "text": "Up",
                  "to": "1",
                  "type": 1,
                  "value": "1"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "red",
                    "value": null
                  },
                  {
                    "color": "green",
                    "value": 1
                  }
                ]
              }
            }
          }
        },
        {
          "title": "Request Rate",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "rate(http_requests_total[5m])",
              "legendFormat": "{{status}}"
            }
          ]
        }
      ]
    },
    {
      "title": "Model Performance",
      "type": "row",
      "panels": [
        {
          "title": "Model Latency",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m]))",
              "legendFormat": "p95"
            },
            {
              "expr": "histogram_quantile(0.50, rate(model_inference_duration_seconds_bucket[5m]))",
              "legendFormat": "p50"
            }
          ]
        },
        {
          "title": "Model Confidence",
          "type": "gauge",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "avg_over_time(model_confidence[5m])"
            }
          ],
          "fieldConfig": {
            "defaults": {
              "min": 0,
              "max": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "red",
                    "value": null
                  },
                  {
                    "color": "yellow",
                    "value": 0.7
                  },
                  {
                    "color": "green",
                    "value": 0.9
                  }
                ]
              }
            }
          }
        }
      ]
    },
    {
      "title": "Pipeline Metrics",
      "type": "row",
      "panels": [
        {
          "title": "Pipeline Latency",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "rate(langchain_pipeline_latency_seconds_sum[5m]) / rate(langchain_pipeline_latency_seconds_count[5m])",
              "legendFormat": "{{stage}}"
            }
          ]
        },
        {
          "title": "Retrieval Success Rate",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "sum(rate(langchain_retrieval_total{status=\"success\"}[5m])) / sum(rate(langchain_retrieval_total[5m]))",
              "legendFormat": "success rate"
            }
          ]
        }
      ]
    },
    {
      "title": "Resource Usage",
      "type": "row",
      "panels": [
        {
          "title": "Memory Usage",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "container_memory_usage_bytes{container=\"ai-concierge\"}"
            }
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "bytes"
            }
          }
        },
        {
          "title": "CPU Usage",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "rate(container_cpu_usage_seconds_total{container=\"ai-concierge\"}[5m])"
            }
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percentunit"
            }
          }
        }
      ]
    },
    {
      "title": "Error Tracking",
      "type": "row",
      "panels": [
        {
          "title": "Error Rate",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
              "legendFormat": "error rate"
            }
          ]
        },
        {
          "title": "Error Distribution",
          "type": "piechart",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "sum(increase(http_requests_total{status=~\"5..\"}[1h])) by (status)",
              "legendFormat": "{{status}}"
            }
          ]
        }
      ]
    },
    {
      "title": "Model Monitoring",
      "type": "row",
      "panels": [
        {
          "title": "Model Drift Score",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "model_drift_score",
              "legendFormat": "{{feature}}"
            }
          ]
        },
        {
          "title": "Bias Metrics",
          "type": "timeseries",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "bias_score",
              "legendFormat": "{{protected_attribute}}"
            }
          ]
        }
      ]
    }
  ],
  "refresh": "5s",
  "schemaVersion": 27,
  "style": "dark",
  "tags": ["ai-concierge"],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "AI Concierge Dashboard",
  "uid": "ai-concierge",
  "version": 1
} 